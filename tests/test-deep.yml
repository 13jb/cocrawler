Crawl:
  MaxDepth: 100000
  MaxCrawledUrls: 5000 # prevent a runaway
  UserAgent: cocrawler-test/0.01

Plugins:
  url_allowed: SeedsHostname

Multiprocess:
  ParseInBurnerSize: 1 # make sure the burner thread gets used
  Affinity: yes

Seeds:
  Hosts:
  - http://test.website/ordinary/0
  - http://test.website/ordinary/1 # makes the robots fetch interlock fire

Logging:
#  LoggingLevel: 3
  Crawllog: crawllog.jsonl
  Robotslog: robotslog.jsonl

UserAgent:
  Style: crawler
  MyPrefix: test-deep
  URL: http://example.com/cocrawler.html

Testing:
  TestHostmapAll: 127.0.0.1:8080
#  TestHostmapAll: localhost:8080 ## aiodns doesn't consult /etc/hosts :-/
  StatsEQ:
    fetch URLs: 1000
    fetch http code=200: 1000
    max urls found on a page: 3
    robots denied: 1
    warc r/r (prefix Testing): 1000
